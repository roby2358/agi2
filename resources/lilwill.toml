# lil Will Model Configuration - Tiny Shakespeare
# Usage: python agi2_train.py resources/lilwill.toml

# Training data sources - list of corpus files
sources = [
    "samples/shakespeare_complete.txt",
    "resources/training/corpus20.txt"
]

model_name = "lilwill"
model_path = "trained/lilwill.pt"

# Training parameters - optimized for speed
epochs = 100
batch_size = 16
learning_rate = 1e-4
seq_len = 512

# Model architecture - smaller for faster training
model_positions = 512
model_embd = 384
model_layer = 3
model_head = 3
model_activation = "gelu"
model_dropout = 0.1

# Device and resume options
device = "auto"
resume = ""

# Generation parameters
max_length = 300
temperature = 0.8
beam_size = 3
model_seed = """
Here lies the voice that taught us our own tongues. His words outlived
 his breath, shaping grief and joy alike, and in their echo we are
 never wholly without him.
"""

# Interactive parameters
max_context_length = 512
